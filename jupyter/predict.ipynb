{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292bce99-e947-4891-870b-b9b223205c8e",
   "metadata": {},
   "source": [
    "# Environment\n",
    "- Ubuntu 24.04\n",
    "- Python 3.10\n",
    "- 해당 노트북 파일과 같은 디렉터리 상에 ./Wildfire 폴더에 대회 데이터셋이 존재해야합니다.\n",
    "  - ./Wildfire/train_img\n",
    "  - ./Wildfire/train_mask\n",
    "  - ./Wildfire/test_img\n",
    "\n",
    "# 주의사항\n",
    "checkpoint 경로 설정은 제일 아래에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93a2add-b188-4889-b4ba-f28c444675b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: albumentations in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (1.12.0)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (0.22.0)\n",
      "Requirement already satisfied: PyYAML in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (4.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (1.4.1.post1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-learn>=1.3.2->albumentations) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-learn>=1.3.2->albumentations) (3.4.0)\n",
      "Requirement already satisfied: torch in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: openmim in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: filelock in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: Click in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (8.1.7)\n",
      "Requirement already satisfied: colorama in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (0.4.6)\n",
      "Requirement already satisfied: model-index in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (0.1.11)\n",
      "Requirement already satisfied: opendatalab in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (0.0.10)\n",
      "Requirement already satisfied: pandas in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (2.2.1)\n",
      "Requirement already satisfied: pip>=19.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (24.0)\n",
      "Requirement already satisfied: requests in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (2.28.2)\n",
      "Requirement already satisfied: rich in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (13.4.2)\n",
      "Requirement already satisfied: tabulate in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pyyaml in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from model-index->openmim) (6.0.1)\n",
      "Requirement already satisfied: markdown in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from model-index->openmim) (3.6)\n",
      "Requirement already satisfied: ordered-set in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from model-index->openmim) (4.1.0)\n",
      "Requirement already satisfied: pycryptodome in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from opendatalab->openmim) (3.20.0)\n",
      "Requirement already satisfied: tqdm in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from opendatalab->openmim) (4.65.2)\n",
      "Requirement already satisfied: openxlab in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from opendatalab->openmim) (0.0.37)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from pandas->openmim) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from pandas->openmim) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from pandas->openmim) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rich->openmim) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rich->openmim) (2.17.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\n",
      "Requirement already satisfied: oss2~=2.17.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openxlab->opendatalab->openmim) (2.17.0)\n",
      "Requirement already satisfied: setuptools~=60.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openxlab->opendatalab->openmim) (60.2.0)\n",
      "Requirement already satisfied: crcmod>=1.7 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n",
      "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.2)\n",
      "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.15.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (42.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
      "Requirement already satisfied: timm in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (0.9.16)\n",
      "Requirement already satisfied: torch in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (2.2.1)\n",
      "Requirement already satisfied: torchvision in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (0.17.1)\n",
      "Requirement already satisfied: pyyaml in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (0.22.1)\n",
      "Requirement already satisfied: safetensors in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (4.65.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.99)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision->timm) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.2.0/index.html\n",
      "Requirement already satisfied: mmengine in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (0.10.3)\n",
      "Requirement already satisfied: addict in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (2.4.0)\n",
      "Requirement already satisfied: matplotlib in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (3.8.3)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (6.0.1)\n",
      "Requirement already satisfied: rich in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (13.4.2)\n",
      "Requirement already satisfied: termcolor in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (2.4.0)\n",
      "Requirement already satisfied: yapf in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (0.40.2)\n",
      "Requirement already satisfied: opencv-python>=3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (4.9.0.80)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (2.9.0.post0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rich->mmengine) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rich->mmengine) (2.17.2)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from yapf->mmengine) (7.1.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from yapf->mmengine) (4.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
      "Requirement already satisfied: rasterio in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (1.3.9)\n",
      "Requirement already satisfied: affine in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (23.2.0)\n",
      "Requirement already satisfied: certifi in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (2024.2.2)\n",
      "Requirement already satisfied: click>=4.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (1.26.4)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (60.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "# 필요 패키지 설치 (현시점 (2024-03-27) 최신버전으로 설치시 문제 없음)\n",
    "! pip install numpy opencv-contrib-python albumentations --upgrade\n",
    "! pip install torch torchvision openmim --upgrade\n",
    "! pip install timm --upgrade\n",
    "! mim install mmengine --upgrade\n",
    "! pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ee8e3-0483-4fee-835b-55d8a14ea44e",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "테스트데이터 로딩을 위한 dataset class입니다.\n",
    "\n",
    "해당 노트북 파일과 같은 디렉터리 상에 Wildfire 폴더에 대회 데이터셋이 존재해야합니다.\n",
    "\n",
    "기본적으로 학습데이터셋에서와 같은 방법으로 7채널 + mean 7채널로 인풋 이미지를 출력합니다. (14x256x256)\n",
    "별도의 어그멘테이션은 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1471cdf-617c-43d1-b86c-f3d3dc1611ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "DATA_ROOT = Path(\"Wildfire\")\n",
    "TRAIN_IMG_DIR = DATA_ROOT / \"train_img\"\n",
    "TRAIN_MASK_DIR = DATA_ROOT / \"train_mask\"\n",
    "TEST_IMG_DIR = DATA_ROOT / \"test_img\"\n",
    "\n",
    "def _imread_float(f: str | Path, input_chs: list[int]):\n",
    "    img = rasterio.open(f).read()[input_chs].transpose((1, 2, 0))\n",
    "    img = img / 65535\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, input_chs: list[int]):\n",
    "        super().__init__()\n",
    "\n",
    "        img_paths = sorted(TEST_IMG_DIR.glob(\"*.tif\"))\n",
    "\n",
    "        self.img_paths = img_paths\n",
    "        self.input_chs = input_chs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path = self.img_paths[idx]\n",
    "\n",
    "        img = _imread_float(img_path, self.input_chs)\n",
    "\n",
    "        # (H, W, C) -> (C, H, W)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "        # Add mean channels\n",
    "        img_mean = np.zeros_like(img)\n",
    "        for i, each_ch in enumerate(img):\n",
    "            if (each_ch > 0).sum() > 0:\n",
    "                img_mean[i] = each_ch[each_ch > 0].mean()\n",
    "\n",
    "        img = np.concatenate([img, img_mean], axis=0)\n",
    "\n",
    "        # sample return\n",
    "        sample = {\"img\": img, \"img_path\": img_path}\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fd323-d6c0-49e2-b747-124294f0fa7b",
   "metadata": {},
   "source": [
    "# UNet Encoder\n",
    "UNet의 인코더 파트입니다.\n",
    "기본적으로 timm라이브러리의 regnetx_002를 가져와서 사용하였습니다.\n",
    "timm에서 제공하는 pretrained weight로 초기화 시켰습니다.\n",
    "해당 pretrained weight는 imagenet 데이터셋으로 학습된것으로 보입니다.\n",
    "https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/regnet.py\n",
    "https://github.com/facebookresearch/pycls/blob/main/MODEL_ZOO.md\n",
    "\n",
    "regnet encoder에서 UNet 생성에 필요없는 fnal_conv와 head layer는 제거 합니다.\n",
    "\n",
    "conv0 레이어를 추가하여, regnet 이전에 붙였습니다.\n",
    "해당 레이어는 2개의 1x1 conv layer로 이루어져있습니다.\n",
    "일반 이미지와는 달리 Wildfire 영상의 scale변화가 샘플마다 컸기 때문에, 1x1 conv layer로 우선 각 픽셀에서 어떠한 정규화가 일어나길 기대햇습니다.\n",
    "\n",
    "regnet의 conv1레이어는 원래 3채널의 RGB 값을 받는 레이어이기 때문에, conv0의 output인 32 채널을 받을 수 있도록, 수정을 가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e98640e-b77e-4b05-be95-0769b9b8877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class RegNetEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        in_ch: int,\n",
    "        empty_out_depths: list[int],\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if name == \"regnetx_002\":\n",
    "            self.model = timm.create_model(\"regnetx_002\", pretrained=True)\n",
    "        elif name == \"regnetx_004\":\n",
    "            self.model = timm.create_model(\"regnetx_004\", pretrained=True)\n",
    "        elif name == \"regnetx_006\":\n",
    "            self.model = timm.create_model(\"regnetx_006\", pretrained=True)\n",
    "        elif name == \"regnetx_008\":\n",
    "            self.model = timm.create_model(\"regnetx_008\", pretrained=True)\n",
    "        else:\n",
    "            raise ValueError(name)\n",
    "\n",
    "        # Remove original fc layer\n",
    "        del self.model.final_conv\n",
    "        del self.model.head\n",
    "\n",
    "        # conv0\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch * 2, 32, kernel_size=1, padding=0, bias=True),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, kernel_size=1, padding=0, bias=True),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # Patch first layer\n",
    "        patch_ch = 32\n",
    "        with torch.no_grad():\n",
    "            orig_weight = self.model.stem.conv.weight.detach()\n",
    "\n",
    "            new_conv = nn.Conv2d(patch_ch, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            new_conv.weight[:] = (\n",
    "                orig_weight.repeat(1, (patch_ch + 2) // 3, 1, 1)[:, :patch_ch] * 3 / patch_ch\n",
    "            )\n",
    "            self.model.stem.conv = new_conv\n",
    "\n",
    "        # ETC\n",
    "        self.empty_out_depths = empty_out_depths\n",
    "\n",
    "    def _get_stages(self) -> list[nn.Module]:\n",
    "        return [\n",
    "            # nn.Identity(),\n",
    "            nn.Sequential(self.conv0, self.model.stem),\n",
    "            self.model.s1,\n",
    "            self.model.s2,\n",
    "            self.model.s3,\n",
    "            self.model.s4,\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def out_channels(self) -> list[int]:\n",
    "        channels = [\n",
    "            # self.model.stem.conv.in_channels,\n",
    "            self.model.stem.conv.out_channels,\n",
    "            self.model.s1.b1.conv1.conv.out_channels,\n",
    "            self.model.s2.b1.conv1.conv.out_channels,\n",
    "            self.model.s3.b1.conv1.conv.out_channels,\n",
    "            self.model.s4.b1.conv1.conv.out_channels,\n",
    "        ]\n",
    "        return [0 if d in self.empty_out_depths else ch for d, ch in enumerate(channels)]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> list[torch.Tensor]:\n",
    "        stages = self._get_stages()\n",
    "\n",
    "        features = []\n",
    "        for depth, stage in enumerate(stages):\n",
    "            x = stage(x)\n",
    "\n",
    "            if depth in self.empty_out_depths:\n",
    "                B, _, H, W = x.shape\n",
    "                empty_tensor = torch.zeros((B, 0, H, W), dtype=x.dtype, device=x.device)\n",
    "                features.append(empty_tensor)\n",
    "            else:\n",
    "                features.append(x)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235a0e9-54b2-48c4-a893-cf1db9c651e3",
   "metadata": {},
   "source": [
    "# UNet Decoder\n",
    "\n",
    "UNet Decoder 파트입니다.\n",
    "업샘플링 layer와 conv layer로 이루어져있는 전형적인 디코더 구조입니다.\n",
    "인코더의 같은 level에서 skip connection 또한 수신하는 구조입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e031294-9b72-4249-8963-6bfa09ee06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Conv2dReLU(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        use_batchnorm=True,\n",
    "    ):\n",
    "\n",
    "        conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=not (use_batchnorm),\n",
    "        )\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if use_batchnorm:\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            bn = nn.Identity()\n",
    "\n",
    "        super().__init__(conv, bn, relu)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch: int,\n",
    "        skip_ch: int,\n",
    "        out_ch: int,\n",
    "        upsample_mode: str,\n",
    "        use_batchnorm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=upsample_mode)\n",
    "\n",
    "        self.conv1 = Conv2dReLU(\n",
    "            in_ch + skip_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "        self.conv2 = Conv2dReLU(\n",
    "            out_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        x = self.upsample(x)\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CenterBlock(nn.Sequential):\n",
    "    def __init__(self, in_ch: int, out_ch: int, use_batchnorm=True):\n",
    "        conv1 = Conv2dReLU(\n",
    "            in_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "        conv2 = Conv2dReLU(\n",
    "            out_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "        super().__init__(conv1, conv2)\n",
    "\n",
    "\n",
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        center_ch: int,\n",
    "        skip_chs: list[int],\n",
    "        decoder_chs: list[int],\n",
    "        upsample_mode: str,\n",
    "        use_batchnorm=True,\n",
    "        use_center_block=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if use_center_block:\n",
    "            self.center = CenterBlock(center_ch, center_ch, use_batchnorm=use_batchnorm)\n",
    "        else:\n",
    "            self.center = nn.Identity()\n",
    "\n",
    "        in_chs = [center_ch] + decoder_chs[:-1]\n",
    "        blocks = [\n",
    "            DecoderBlock(in_ch, skip_ch, out_ch, upsample_mode, use_batchnorm=use_batchnorm)\n",
    "            for in_ch, skip_ch, out_ch in zip(in_chs, skip_chs, decoder_chs, strict=True)\n",
    "        ]\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, center_feat, skip_feats):\n",
    "\n",
    "        x = self.center(center_feat)\n",
    "        xs = []\n",
    "        for decoder_block, skip_feat in zip(self.blocks, skip_feats, strict=True):\n",
    "            x = decoder_block(x, skip_feat)\n",
    "            xs.append(x)\n",
    "\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd9c81-19f2-4ac9-b7b4-84cd85882417",
   "metadata": {},
   "source": [
    "# UNet\n",
    "위에서 만든 인코더와 디코더를 합쳐 하나의 UNet을 만드는 코드입니다.\n",
    "\n",
    "추가적으로 mmengine에서 사용하는 BaseModel도 정의되어 있습니다.\n",
    "BaseModel 내부에 loss를 계산하는 부분을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2303444d-8c7f-4e1b-9347-6cfd6c9b3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from mmengine.model import BaseModel as MMBaseModel\n",
    "from mmengine.registry import MODELS\n",
    "from torch import nn\n",
    "\n",
    "class Conv2dUpsample(nn.Sequential):\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, upsampling: int):\n",
    "        conv2d = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        upsampling = (\n",
    "            nn.Upsample(scale_factor=upsampling, mode=\"bilinear\")\n",
    "            if upsampling > 1\n",
    "            else nn.Identity()\n",
    "        )\n",
    "        super().__init__(conv2d, upsampling)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = MODELS.build(encoder)\n",
    "        encoder_chs = self.encoder.out_channels\n",
    "\n",
    "        decoder[\"center_ch\"] = encoder_chs[-1]\n",
    "        decoder[\"skip_chs\"] = encoder_chs[::-1][1:]\n",
    "        self.decoder = MODELS.build(decoder)\n",
    "\n",
    "        # head\n",
    "        decoder_chs = decoder[\"decoder_chs\"]\n",
    "        self.head0 = Conv2dUpsample(decoder_chs[-1], 1, kernel_size=3, upsampling=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs[\"img\"]  # (B, C, H, W)\n",
    "\n",
    "        # Forward Pass\n",
    "        encoded = self.encoder(x)\n",
    "        decoder_out = self.decoder(encoded[-1], encoded[::-1][1:])\n",
    "\n",
    "        # output_h4 = self.head4(decoder_out[-5])\n",
    "        # output_h3 = self.head3(decoder_out[-4])\n",
    "        # output_h2 = self.head2(decoder_out[-3])\n",
    "        # output_h1 = self.head1(decoder_out[-2])\n",
    "        output_h0 = self.head0(decoder_out[-1])\n",
    "\n",
    "        # output_h0 = torch.sigmoid(output_h0)\n",
    "\n",
    "        return output_h0\n",
    "\n",
    "\n",
    "class OurBaseModel(MMBaseModel):\n",
    "    def __init__(self, unet):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = MODELS.build(unet)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, mode, **inputs):\n",
    "        y_pred = self.unet(inputs)  # (B, 1, H, W)\n",
    "        y_gt = inputs[\"mask\"]  # (B, 1, H, W)\n",
    "\n",
    "        if mode == \"loss\":\n",
    "            lovasz_loss = lovasz_hinge(y_pred, y_gt, use_elu=True)\n",
    "            return {\"lovasz_loss\": lovasz_loss}\n",
    "        elif mode == \"predict\":\n",
    "            return torch.sigmoid(y_pred), y_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de8f27-9a03-4649-8149-da2cd3ec2f22",
   "metadata": {},
   "source": [
    "# Run Prediction\n",
    "테스트셋 추론 관련된 config를 세팅하고 추론을 수행하는 코드입니다.\n",
    "1분 넘게 걸립니다.\n",
    "\n",
    "TTA를 수행합니다.\n",
    "원본, H_Flip, V_FLIP, HV_Flip 이미지들에 대해서 각각 추론을 하고 평균을 합니다.\n",
    "Sigmoid output이기 때문엔 segmentation threshold는 0.5로 지정하였습니다.\n",
    "\n",
    "수행이 끝나면 노트북이 있는 폴더에 \"y_pred.pkl\"파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04cffa1-13bc-498a-9ea7-3f8e95c9369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmengine.registry import MODELS\n",
    "from mmengine.runner.checkpoint import load_checkpoint\n",
    "\n",
    "@torch.no_grad()\n",
    "def main(ckpt_path: str):\n",
    "\n",
    "    input_chs = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    model = dict(\n",
    "        type=OurBaseModel,\n",
    "        unet=dict(\n",
    "            type=UNet,\n",
    "            encoder=dict(\n",
    "                type=RegNetEncoder, name=\"regnetx_002\", in_ch=len(input_chs), empty_out_depths=[]\n",
    "            ),\n",
    "            decoder=dict(\n",
    "                type=UNetDecoder,\n",
    "                decoder_chs=[128, 64, 48, 32],  # , 24],\n",
    "                upsample_mode=\"nearest\",\n",
    "                use_batchnorm=True,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = MODELS.build(model).to(device)\n",
    "    load_checkpoint(\n",
    "        model, str(ckpt_path), map_location=\"cpu\", strict=True, revise_keys=[(r\"module\\.\", \"\")]\n",
    "    )\n",
    "\n",
    "    dataset = TestDataset(input_chs=[0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    img_paths = []\n",
    "    for idx, x in enumerate(dataset):\n",
    "        img_x = torch.tensor(x[\"img\"]).to(device)\n",
    "        img_x = torch.stack([img_x, img_x.flip(1), img_x.flip(2), img_x.flip([1, 2])])\n",
    "\n",
    "        y_pred, _ = model.forward(mode=\"predict\", img=img_x, mask=None)\n",
    "\n",
    "        y_pred[1] = y_pred[1].flip(1)\n",
    "        y_pred[2] = y_pred[2].flip(2)\n",
    "        y_pred[3] = y_pred[3].flip([1, 2])\n",
    "        y_pred = y_pred.mean(0)\n",
    "\n",
    "        preds.append(y_pred.squeeze().cpu().numpy())\n",
    "        img_paths.append(x[\"img_path\"])\n",
    "\n",
    "    preds = np.stack(preds)\n",
    "    preds = (preds > 0.5).astype(np.uint8)\n",
    "\n",
    "    y_pred_dict = {}\n",
    "    for img_path, pred in zip(img_paths, preds, strict=True):\n",
    "        y_pred_dict[img_path.name] = pred\n",
    "\n",
    "\n",
    "    joblib.dump(y_pred_dict, \"./y_pred.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde16e80-7d3d-4666-8f74-90552d5c8072",
   "metadata": {},
   "source": [
    "# 체크포인트 파일 경로 설정 필요\n",
    "현재는 leaderboard 체크포인트로 설정되어있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f164dc-956d-4d89-92dc-bc85a06d7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: leaderboard_epoch_130.pth\n"
     ]
    }
   ],
   "source": [
    "main(\"leaderboard_epoch_130.pth\")\n",
    "# main(\"Logs/xxxxxx/epoch_xxx.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
