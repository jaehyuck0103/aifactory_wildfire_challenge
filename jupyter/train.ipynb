{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292bce99-e947-4891-870b-b9b223205c8e",
   "metadata": {},
   "source": [
    "# Environment\n",
    "- Ubuntu 24.04\n",
    "- Python 3.10\n",
    "- 해당 노트북 파일과 같은 디렉터리 상에 ./Wildfire 폴더에 대회 데이터셋이 존재해야합니다.\n",
    "  - ./Wildfire/train_img\n",
    "  - ./Wildfire/train_mask\n",
    "  - ./Wildfire/test_img\n",
    "\n",
    "# 주의사항\n",
    "max_epoch은 150으로 잡혀있습니다.\n",
    "단일 RTX4090에서도 이틀넘게 걸리는 긴 시간의 학습이 필요합니다.\n",
    "하지만, 10epoch마다 체크포인트가 \"Logs/{학습시작시간}\" 폴더에 저장되는데, 50epoch정도면 충분히 최고 성능으로 수렴하는 편입니다.\n",
    "그러므로, 빠르게 재현성을 확인하시고자 한다면, 한 번씩 중간 epoch의 체크포인트로 점수를 확인해보시길 권장드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93a2add-b188-4889-b4ba-f28c444675b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-1.4.2-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting scipy>=1.10.0 (from albumentations)\n",
      "  Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations)\n",
      "  Using cached scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from albumentations) (4.10.0)\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations)\n",
      "  Using cached scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting opencv-python-headless>=4.9.0 (from albumentations)\n",
      "  Using cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting networkx>=2.8 (from scikit-image>=0.21.0->albumentations)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pillow>=9.0.1 (from scikit-image>=0.21.0->albumentations)\n",
      "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting imageio>=2.27 (from scikit-image>=0.21.0->albumentations)\n",
      "  Using cached imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations)\n",
      "  Using cached tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
      "Collecting lazy_loader>=0.3 (from scikit-image>=0.21.0->albumentations)\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.3.2->albumentations)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=1.3.2->albumentations)\n",
      "  Using cached threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.3 MB)\n",
      "Using cached albumentations-1.4.2-py3-none-any.whl (133 kB)\n",
      "Using cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "Using cached scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "Using cached scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "Using cached imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Using cached tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: threadpoolctl, pillow, numpy, networkx, lazy_loader, joblib, tifffile, scipy, opencv-python-headless, opencv-contrib-python, imageio, scikit-learn, scikit-image, albumentations\n",
      "Successfully installed albumentations-1.4.2 imageio-2.34.0 joblib-1.3.2 lazy_loader-0.3 networkx-3.2.1 numpy-1.26.4 opencv-contrib-python-4.9.0.80 opencv-python-headless-4.9.0.80 pillow-10.2.0 scikit-image-0.22.0 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.4.0 tifffile-2024.2.12\n",
      "Collecting torch\n",
      "  Using cached torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting openmim\n",
      "  Using cached openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Collecting Click (from openmim)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting colorama (from openmim)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting model-index (from openmim)\n",
      "  Using cached model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim)\n",
      "  Using cached opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pandas (from openmim)\n",
      "  Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pip>=19.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (24.0)\n",
      "Requirement already satisfied: requests in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from openmim) (2.31.0)\n",
      "Collecting rich (from openmim)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tabulate (from openmim)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pyyaml in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from model-index->openmim) (6.0.1)\n",
      "Collecting markdown (from model-index->openmim)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ordered-set (from model-index->openmim)\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim)\n",
      "  Using cached pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting tqdm (from opendatalab->openmim)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting openxlab (from opendatalab->openmim)\n",
      "  Using cached openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->openmim) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from pandas->openmim) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->openmim)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->openmim)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->openmim)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rich->openmim) (2.17.2)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->openmim)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
      "  Using cached oss2-2.17.0-py3-none-any.whl\n",
      "Collecting pytz>=2020.1 (from pandas->openmim)\n",
      "  Using cached pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests (from openmim)\n",
      "  Using cached requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich (from openmim)\n",
      "  Using cached rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
      "  Using cached setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tqdm (from opendatalab->openmim)\n",
      "  Using cached tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Using cached crcmod-1.7-cp310-cp310-linux_x86_64.whl\n",
      "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Using cached aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Using cached aliyun_python_sdk_core-2.15.0-py3-none-any.whl\n",
      "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting cryptography>=2.6.0 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
      "Using cached torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Using cached torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "Using cached openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Using cached opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached openxlab-0.0.37-py3-none-any.whl (302 kB)\n",
      "Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Using cached rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "Using cached pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
      "Using cached tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
      "Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Using cached pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
      "Using cached aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
      "Using cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, mpmath, crcmod, urllib3, tzdata, tqdm, tabulate, sympy, setuptools, pycryptodome, ordered-set, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mdurl, markdown, jmespath, fsspec, filelock, colorama, Click, triton, requests, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, model-index, markdown-it-py, cryptography, rich, nvidia-cusolver-cu12, aliyun-python-sdk-core, torch, aliyun-python-sdk-kms, torchvision, oss2, openxlab, opendatalab, openmim\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.2.0\n",
      "    Uninstalling setuptools-69.2.0:\n",
      "      Successfully uninstalled setuptools-69.2.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-server 2.25.4 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Click-8.1.7 aliyun-python-sdk-core-2.15.0 aliyun-python-sdk-kms-2.16.2 colorama-0.4.6 crcmod-1.7 cryptography-42.0.5 filelock-3.13.3 fsspec-2024.3.1 jmespath-0.10.0 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 model-index-0.1.11 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.37 ordered-set-4.1.0 oss2-2.17.0 pandas-2.2.1 pycryptodome-3.20.0 pytz-2023.4 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 sympy-1.12 tabulate-0.9.0 torch-2.2.1 torchvision-0.17.1 tqdm-4.65.2 triton-2.2.0 tzdata-2024.1 urllib3-1.26.18\n",
      "Collecting timm\n",
      "  Using cached timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: torch in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (2.2.1)\n",
      "Requirement already satisfied: torchvision in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (0.17.1)\n",
      "Requirement already satisfied: pyyaml in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from timm) (6.0.1)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Using cached huggingface_hub-0.22.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (4.65.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from huggingface_hub->timm) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torch->timm) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.99)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from torchvision->timm) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Using cached timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "Using cached huggingface_hub-0.22.1-py3-none-any.whl (388 kB)\n",
      "Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Installing collected packages: safetensors, huggingface_hub, timm\n",
      "Successfully installed huggingface_hub-0.22.1 safetensors-0.4.2 timm-0.9.16\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.2.0/index.html\n",
      "Collecting mmengine\n",
      "  Using cached mmengine-0.10.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting addict (from mmengine)\n",
      "  Using cached addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting matplotlib (from mmengine)\n",
      "  Using cached matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (6.0.1)\n",
      "Requirement already satisfied: rich in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from mmengine) (13.4.2)\n",
      "Collecting termcolor (from mmengine)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting yapf (from mmengine)\n",
      "  Using cached yapf-0.40.2-py3-none-any.whl.metadata (45 kB)\n",
      "Collecting opencv-python>=3 (from mmengine)\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mmengine)\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mmengine)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mmengine)\n",
      "  Using cached fonttools-4.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mmengine)\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mmengine)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from matplotlib->mmengine) (2.9.0.post0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rich->mmengine) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rich->mmengine) (2.17.2)\n",
      "Collecting importlib-metadata>=6.6.0 (from yapf->mmengine)\n",
      "  Using cached importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from yapf->mmengine) (4.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=6.6.0->yapf->mmengine)\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
      "Using cached mmengine-0.10.3-py3-none-any.whl (451 kB)\n",
      "Using cached opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "Using cached addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached yapf-0.40.2-py3-none-any.whl (254 kB)\n",
      "Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Installing collected packages: addict, zipp, termcolor, pyparsing, opencv-python, kiwisolver, fonttools, cycler, contourpy, matplotlib, importlib-metadata, yapf, mmengine\n",
      "Successfully installed addict-2.4.0 contourpy-1.2.0 cycler-0.12.1 fonttools-4.50.0 importlib-metadata-7.1.0 kiwisolver-1.4.5 matplotlib-3.8.3 mmengine-0.10.3 opencv-python-4.9.0.80 pyparsing-3.1.2 termcolor-2.4.0 yapf-0.40.2 zipp-3.18.1\n",
      "Collecting rasterio\n",
      "  Using cached rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Using cached affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (23.2.0)\n",
      "Requirement already satisfied: certifi in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (2024.2.2)\n",
      "Requirement already satisfied: click>=4.0 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (1.26.4)\n",
      "Collecting snuggs>=1.4.1 (from rasterio)\n",
      "  Using cached snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: setuptools in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from rasterio) (60.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
      "Using cached rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Using cached snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.3.9 snuggs-1.4.7\n"
     ]
    }
   ],
   "source": [
    "# 필요 패키지 설치 (현시점 (2024-03-27) 최신버전으로 설치시 문제 없음)\n",
    "! pip install numpy opencv-contrib-python albumentations --upgrade\n",
    "! pip install torch torchvision openmim --upgrade\n",
    "! pip install timm --upgrade\n",
    "! mim install mmengine --upgrade\n",
    "! pip install rasterio --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2730d-836a-43e6-abcc-5d5956708cad",
   "metadata": {},
   "source": [
    "# Lovasz Loss\n",
    "https://github.com/bermanmaxim/LovaszSoftmax/blob/master/pytorch/lovasz_losses.py\n",
    "\n",
    "위의 공식 사이트의 코드를 그대로 가져왔고, lovasz_hinge에서 relu대신 elu를 사용하는 option만 추가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2e3f20-aa92-46e6-9340-a959a4b51b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:201: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:201: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_197343/4294850633.py:201: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if classes is \"present\" and fg.sum() == 0:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "try:\n",
    "    from itertools import ifilterfalse\n",
    "except ImportError:  # py3k\n",
    "    from itertools import filterfalse as ifilterfalse\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1.0 - intersection / union\n",
    "    if p > 1:  # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def iou_binary(preds, labels, EMPTY=1.0, ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / float(union)\n",
    "        ious.append(iou)\n",
    "    iou = mean(ious)  # mean accross images if per_image\n",
    "    return 100 * iou\n",
    "\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1.0, ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []\n",
    "        for i in range(C):\n",
    "            if (\n",
    "                i != ignore\n",
    "            ):  # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / float(union))\n",
    "        ious.append(iou)\n",
    "    ious = [mean(iou) for iou in zip(*ious)]  # mean accross images if per_image\n",
    "    return 100 * np.array(ious)\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None, use_elu=False):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(\n",
    "            lovasz_hinge_flat(\n",
    "                *flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore), use_elu=use_elu\n",
    "            )\n",
    "            for log, lab in zip(logits, labels)\n",
    "        )\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore), use_elu=use_elu)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels, use_elu=False):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.0\n",
    "    signs = 2.0 * labels.float() - 1.0\n",
    "    errors = 1.0 - logits * Variable(signs)\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "\n",
    "    if use_elu:\n",
    "        loss = torch.dot(F.elu(errors_sorted) + 1, Variable(grad))\n",
    "    else:  # original\n",
    "        loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = labels != ignore\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "class StableBCELoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "        super(StableBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        neg_abs = -input.abs()\n",
    "        loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "def binary_xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Cross entropy loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    logits, labels = flatten_binary_scores(logits, labels, ignore)\n",
    "    loss = StableBCELoss()(logits, Variable(labels.float()))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes=\"present\", per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n",
    "              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(\n",
    "            lovasz_softmax_flat(\n",
    "                *flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes\n",
    "            )\n",
    "            for prob, lab in zip(probas, labels)\n",
    "        )\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes=\"present\"):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "    \"\"\"\n",
    "    if probas.numel() == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return probas * 0.0\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    class_to_sum = list(range(C)) if classes in [\"all\", \"present\"] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = (labels == c).float()  # foreground for class c\n",
    "        if classes is \"present\" and fg.sum() == 0:\n",
    "            continue\n",
    "        if C == 1:\n",
    "            if len(classes) > 1:\n",
    "                raise ValueError(\"Sigmoid output possible only with 1 class\")\n",
    "            class_pred = probas[:, 0]\n",
    "        else:\n",
    "            class_pred = probas[:, c]\n",
    "        errors = (Variable(fg) - class_pred).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return mean(losses)\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    if probas.dim() == 3:\n",
    "        # assumes output of a sigmoid layer\n",
    "        B, H, W = probas.size()\n",
    "        probas = probas.view(B, 1, H, W)\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = labels != ignore\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n",
    "\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS ---------------------------\n",
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == \"raise\":\n",
    "            raise ValueError(\"Empty mean\")\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ee8e3-0483-4fee-835b-55d8a14ea44e",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "학습데이터 로딩을 위한 dataset class입니다.\n",
    "k-fold 교차검증이 가능하도록 하여 실험에서 사용하였습니다.\n",
    "본 노트북에서는 전체 학습데이터를 사용하여 최종 모델을 학습하는 케이스만 보여주기 때문에, k-fold 교차 검증을 사용하진 않습니다.\n",
    "(WildfireDataset을 초기화할때 kfold_N=0으로 k-fold교차 검증을 사용하지 않고 전체 학습데이터를 로딩)\n",
    "\n",
    "해당 노트북 파일과 같은 디렉터리 상에 Wildfire 폴더에 대회 데이터셋이 존재해야합니다.\n",
    "\n",
    "train 모드에서는 데이터 augmentation이 이루어집니다.\n",
    "\"transform = ...\" 코드를 보면 확인할 수 있고, padding, random crop, horizontal flip, vertical flip을 사용합니다.\n",
    "\n",
    "WildfireDataset을 초기화 할 때, input_chs로 이미지의 어떤 채널을 이용할 지 선택할 수 있습니다.\n",
    "dataset을 로딩하면 총 10개의 채널이 있고, 뒷쪽 3개 채널은 큰 의미가 없어보였기에, 본 실험에서는 앞쪽 7개 채널만 이용하였습니다.\n",
    "이미지를 로딩하면 기본적으로 uint16타입이기에, float32로 바꾸면서 65535로 나누어 주었습니다.\n",
    "\n",
    "7개 채널의 mean값을 입력 이미지의 채널에 추가 하였습니다. (코드상에 # Add mean channels 부분)\n",
    "일반 이미지에 비해서 샘플 마다의 data 분포의 변화가 큰 것 같아서, 딥러닝 네트워크에 정보를 주고자 하였습니다.\n",
    "그래서 최종적으로는 14x256x256 크기의 이미지와, 1x256x256 크기의 마스크를 출력합니다.\n",
    "\n",
    "WildfireDataset을 초기화 할 때, epoch_scale_factor를 조절하면, 데이터셋의 epoch 양을 조절할 수 있습니다.\n",
    "본 실험에서는 epoch_scale_factor=10으로 두었습니다.\n",
    "데이터셋의 크기가 비교적 작아서 학습 epoch이 금방 변화하였기에, epoch 변경 단계마다 있는 약간의 오버헤드를 피하고 싶어서 10으로 두었습니다.\n",
    "본 코드에서 100epoch은 실제 데이터셋 기준으로는 1000epoch에 해당한다고 보면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1471cdf-617c-43d1-b86c-f3d3dc1611ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "DATA_ROOT = Path(\"Wildfire\")\n",
    "TRAIN_IMG_DIR = DATA_ROOT / \"train_img\"\n",
    "TRAIN_MASK_DIR = DATA_ROOT / \"train_mask\"\n",
    "TEST_IMG_DIR = DATA_ROOT / \"test_img\"\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.PadIfNeeded(256 * 2, 256 * 2, border_mode=cv2.BORDER_REFLECT_101),\n",
    "                A.PadIfNeeded(256 * 2, 256 * 2, border_mode=cv2.BORDER_WRAP),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.RandomCrop(width=256, height=256),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _imread_float(f: str | Path, input_chs: list[int]):\n",
    "    img = rasterio.open(f).read()[input_chs].transpose((1, 2, 0))\n",
    "    img = img / 65535\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "class WildfireDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str,\n",
    "        epoch_scale_factor: float,\n",
    "        kfold_N: int,\n",
    "        kfold_I: int,\n",
    "        input_chs: list[int],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert mode in [\"train\", \"val\"]\n",
    "\n",
    "        img_paths = sorted(TRAIN_IMG_DIR.glob(\"*.tif\"))\n",
    "        mask_paths = [TRAIN_MASK_DIR / x.name.replace(\"img\", \"mask\") for x in img_paths]\n",
    "        num_imgs = len(img_paths)\n",
    "\n",
    "        if kfold_N == 0:  # Not use kfold, Use all training data.\n",
    "            self.idx_map = list(range(num_imgs))\n",
    "            assert mode == \"train\"\n",
    "        else:\n",
    "            if Path(\"/tmp/coverage_labels.npy\").exists():\n",
    "                coverage_labels = np.load(\"/tmp/coverage_labels.npy\")\n",
    "            else:\n",
    "                coverages = []\n",
    "                for x in mask_paths:\n",
    "                    mask = cv2.imread(str(x), cv2.IMREAD_UNCHANGED)\n",
    "                    coverages.append(mask.sum())\n",
    "                coverages = np.array(coverages)\n",
    "                hist = np.histogram(np.log(coverages))\n",
    "                coverage_labels = np.digitize(np.log(coverages), hist[1], right=True)\n",
    "                np.save(\"/tmp/coverage_labels.npy\", coverage_labels)\n",
    "\n",
    "            # coverage_labels = np.zeros(num_imgs, dtype=int)\n",
    "\n",
    "            kf = StratifiedKFold(n_splits=kfold_N, shuffle=True, random_state=910103)\n",
    "            train_idx, val_idx = list(kf.split(np.zeros(num_imgs), coverage_labels))[kfold_I]\n",
    "\n",
    "            if mode == \"train\":\n",
    "                self.idx_map = train_idx\n",
    "            elif mode == \"val\":\n",
    "                self.idx_map = val_idx\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown Mode {mode}\")\n",
    "\n",
    "        #\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.epoch_scale_factor = epoch_scale_factor\n",
    "        self.mode = mode\n",
    "        self.input_chs = input_chs\n",
    "\n",
    "    def __getitem__(self, _idx):\n",
    "        if _idx >= len(self):\n",
    "            raise IndexError()\n",
    "\n",
    "        if self.epoch_scale_factor < 1:\n",
    "            _idx += len(self) * random.randrange(math.ceil(1 / self.epoch_scale_factor))\n",
    "\n",
    "        idx = self.idx_map[_idx % len(self.idx_map)]\n",
    "\n",
    "        img_path = self.img_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        img = _imread_float(img_path, self.input_chs)\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            transformed = transform(image=img, mask=mask)\n",
    "            img = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        else:\n",
    "            # no augmentation\n",
    "            pass\n",
    "\n",
    "        # (H, W, C) -> (C, H, W)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        mask = np.expand_dims(mask, axis=0).astype(np.float32)\n",
    "\n",
    "        # Add mean channels\n",
    "        img_mean = np.zeros_like(img)\n",
    "        for i, each_ch in enumerate(img):\n",
    "            if (each_ch > 0).sum() > 0:\n",
    "                img_mean[i] = each_ch[each_ch > 0].mean()\n",
    "\n",
    "        img = np.concatenate([img, img_mean], axis=0)\n",
    "\n",
    "        # sample return\n",
    "        sample = {\"img\": img, \"mask\": mask}\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return round(len(self.idx_map) * self.epoch_scale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fd323-d6c0-49e2-b747-124294f0fa7b",
   "metadata": {},
   "source": [
    "# UNet Encoder\n",
    "UNet의 인코더 파트입니다.\n",
    "기본적으로 timm라이브러리의 regnetx_002를 가져와서 사용하였습니다.\n",
    "timm에서 제공하는 pretrained weight로 초기화 시켰습니다.\n",
    "해당 pretrained weight는 imagenet 데이터셋으로 학습된것으로 보입니다.\n",
    "https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/regnet.py\n",
    "https://github.com/facebookresearch/pycls/blob/main/MODEL_ZOO.md\n",
    "\n",
    "regnet encoder에서 UNet 생성에 필요없는 fnal_conv와 head layer는 제거 합니다.\n",
    "\n",
    "conv0 레이어를 추가하여, regnet 이전에 붙였습니다.\n",
    "해당 레이어는 2개의 1x1 conv layer로 이루어져있습니다.\n",
    "일반 이미지와는 달리 Wildfire 영상의 scale변화가 샘플마다 컸기 때문에, 1x1 conv layer로 우선 각 픽셀에서 어떠한 정규화가 일어나길 기대햇습니다.\n",
    "\n",
    "regnet의 conv1레이어는 원래 3채널의 RGB 값을 받는 레이어이기 때문에, conv0의 output인 32 채널을 받을 수 있도록, 수정을 가하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e98640e-b77e-4b05-be95-0769b9b8877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jae/Utils/python_venvs/base3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class RegNetEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        in_ch: int,\n",
    "        empty_out_depths: list[int],\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if name == \"regnetx_002\":\n",
    "            self.model = timm.create_model(\"regnetx_002\", pretrained=True)\n",
    "        elif name == \"regnetx_004\":\n",
    "            self.model = timm.create_model(\"regnetx_004\", pretrained=True)\n",
    "        elif name == \"regnetx_006\":\n",
    "            self.model = timm.create_model(\"regnetx_006\", pretrained=True)\n",
    "        elif name == \"regnetx_008\":\n",
    "            self.model = timm.create_model(\"regnetx_008\", pretrained=True)\n",
    "        else:\n",
    "            raise ValueError(name)\n",
    "\n",
    "        # Remove original fc layer\n",
    "        del self.model.final_conv\n",
    "        del self.model.head\n",
    "\n",
    "        # conv0\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch * 2, 32, kernel_size=1, padding=0, bias=True),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, kernel_size=1, padding=0, bias=True),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # Patch first layer\n",
    "        patch_ch = 32\n",
    "        with torch.no_grad():\n",
    "            orig_weight = self.model.stem.conv.weight.detach()\n",
    "\n",
    "            new_conv = nn.Conv2d(patch_ch, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            new_conv.weight[:] = (\n",
    "                orig_weight.repeat(1, (patch_ch + 2) // 3, 1, 1)[:, :patch_ch] * 3 / patch_ch\n",
    "            )\n",
    "            self.model.stem.conv = new_conv\n",
    "\n",
    "        # ETC\n",
    "        self.empty_out_depths = empty_out_depths\n",
    "\n",
    "    def _get_stages(self) -> list[nn.Module]:\n",
    "        return [\n",
    "            # nn.Identity(),\n",
    "            nn.Sequential(self.conv0, self.model.stem),\n",
    "            self.model.s1,\n",
    "            self.model.s2,\n",
    "            self.model.s3,\n",
    "            self.model.s4,\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def out_channels(self) -> list[int]:\n",
    "        channels = [\n",
    "            # self.model.stem.conv.in_channels,\n",
    "            self.model.stem.conv.out_channels,\n",
    "            self.model.s1.b1.conv1.conv.out_channels,\n",
    "            self.model.s2.b1.conv1.conv.out_channels,\n",
    "            self.model.s3.b1.conv1.conv.out_channels,\n",
    "            self.model.s4.b1.conv1.conv.out_channels,\n",
    "        ]\n",
    "        return [0 if d in self.empty_out_depths else ch for d, ch in enumerate(channels)]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> list[torch.Tensor]:\n",
    "        stages = self._get_stages()\n",
    "\n",
    "        features = []\n",
    "        for depth, stage in enumerate(stages):\n",
    "            x = stage(x)\n",
    "\n",
    "            if depth in self.empty_out_depths:\n",
    "                B, _, H, W = x.shape\n",
    "                empty_tensor = torch.zeros((B, 0, H, W), dtype=x.dtype, device=x.device)\n",
    "                features.append(empty_tensor)\n",
    "            else:\n",
    "                features.append(x)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235a0e9-54b2-48c4-a893-cf1db9c651e3",
   "metadata": {},
   "source": [
    "# UNet Decoder\n",
    "\n",
    "UNet Decoder 파트입니다.\n",
    "업샘플링 layer와 conv layer로 이루어져있는 전형적인 디코더 구조입니다.\n",
    "인코더의 같은 level에서 skip connection 또한 수신하는 구조입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e031294-9b72-4249-8963-6bfa09ee06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Conv2dReLU(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        use_batchnorm=True,\n",
    "    ):\n",
    "\n",
    "        conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=not (use_batchnorm),\n",
    "        )\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if use_batchnorm:\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            bn = nn.Identity()\n",
    "\n",
    "        super().__init__(conv, bn, relu)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch: int,\n",
    "        skip_ch: int,\n",
    "        out_ch: int,\n",
    "        upsample_mode: str,\n",
    "        use_batchnorm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=upsample_mode)\n",
    "\n",
    "        self.conv1 = Conv2dReLU(\n",
    "            in_ch + skip_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "        self.conv2 = Conv2dReLU(\n",
    "            out_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        x = self.upsample(x)\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CenterBlock(nn.Sequential):\n",
    "    def __init__(self, in_ch: int, out_ch: int, use_batchnorm=True):\n",
    "        conv1 = Conv2dReLU(\n",
    "            in_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "        conv2 = Conv2dReLU(\n",
    "            out_ch,\n",
    "            out_ch,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            use_batchnorm=use_batchnorm,\n",
    "        )\n",
    "        super().__init__(conv1, conv2)\n",
    "\n",
    "\n",
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        center_ch: int,\n",
    "        skip_chs: list[int],\n",
    "        decoder_chs: list[int],\n",
    "        upsample_mode: str,\n",
    "        use_batchnorm=True,\n",
    "        use_center_block=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if use_center_block:\n",
    "            self.center = CenterBlock(center_ch, center_ch, use_batchnorm=use_batchnorm)\n",
    "        else:\n",
    "            self.center = nn.Identity()\n",
    "\n",
    "        in_chs = [center_ch] + decoder_chs[:-1]\n",
    "        blocks = [\n",
    "            DecoderBlock(in_ch, skip_ch, out_ch, upsample_mode, use_batchnorm=use_batchnorm)\n",
    "            for in_ch, skip_ch, out_ch in zip(in_chs, skip_chs, decoder_chs, strict=True)\n",
    "        ]\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, center_feat, skip_feats):\n",
    "\n",
    "        x = self.center(center_feat)\n",
    "        xs = []\n",
    "        for decoder_block, skip_feat in zip(self.blocks, skip_feats, strict=True):\n",
    "            x = decoder_block(x, skip_feat)\n",
    "            xs.append(x)\n",
    "\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd9c81-19f2-4ac9-b7b4-84cd85882417",
   "metadata": {},
   "source": [
    "# UNet\n",
    "위에서 만든 인코더와 디코더를 합쳐 하나의 UNet을 만드는 코드입니다.\n",
    "\n",
    "추가적으로 mmengine에서 사용하는 BaseModel도 정의되어 있습니다.\n",
    "BaseModel 내부에 loss를 계산하는 부분을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2303444d-8c7f-4e1b-9347-6cfd6c9b3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from mmengine.model import BaseModel as MMBaseModel\n",
    "from mmengine.registry import MODELS\n",
    "from torch import nn\n",
    "\n",
    "class Conv2dUpsample(nn.Sequential):\n",
    "    def __init__(self, in_ch: int, out_ch: int, kernel_size: int, upsampling: int):\n",
    "        conv2d = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        upsampling = (\n",
    "            nn.Upsample(scale_factor=upsampling, mode=\"bilinear\")\n",
    "            if upsampling > 1\n",
    "            else nn.Identity()\n",
    "        )\n",
    "        super().__init__(conv2d, upsampling)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = MODELS.build(encoder)\n",
    "        encoder_chs = self.encoder.out_channels\n",
    "\n",
    "        decoder[\"center_ch\"] = encoder_chs[-1]\n",
    "        decoder[\"skip_chs\"] = encoder_chs[::-1][1:]\n",
    "        self.decoder = MODELS.build(decoder)\n",
    "\n",
    "        # head\n",
    "        decoder_chs = decoder[\"decoder_chs\"]\n",
    "        self.head0 = Conv2dUpsample(decoder_chs[-1], 1, kernel_size=3, upsampling=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs[\"img\"]  # (B, C, H, W)\n",
    "\n",
    "        # Forward Pass\n",
    "        encoded = self.encoder(x)\n",
    "        decoder_out = self.decoder(encoded[-1], encoded[::-1][1:])\n",
    "\n",
    "        # output_h4 = self.head4(decoder_out[-5])\n",
    "        # output_h3 = self.head3(decoder_out[-4])\n",
    "        # output_h2 = self.head2(decoder_out[-3])\n",
    "        # output_h1 = self.head1(decoder_out[-2])\n",
    "        output_h0 = self.head0(decoder_out[-1])\n",
    "\n",
    "        # output_h0 = torch.sigmoid(output_h0)\n",
    "\n",
    "        return output_h0\n",
    "\n",
    "\n",
    "class OurBaseModel(MMBaseModel):\n",
    "    def __init__(self, unet):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = MODELS.build(unet)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, mode, **inputs):\n",
    "        y_pred = self.unet(inputs)  # (B, 1, H, W)\n",
    "        y_gt = inputs[\"mask\"]  # (B, 1, H, W)\n",
    "\n",
    "        if mode == \"loss\":\n",
    "            lovasz_loss = lovasz_hinge(y_pred, y_gt, use_elu=True)\n",
    "            return {\"lovasz_loss\": lovasz_loss}\n",
    "        elif mode == \"predict\":\n",
    "            return torch.sigmoid(y_pred), y_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de8f27-9a03-4649-8149-da2cd3ec2f22",
   "metadata": {},
   "source": [
    "# Run Training\n",
    "학습과 관련된 config를 세팅하고 학습을 시작하는 코드입니다.\n",
    "\n",
    "config의 네트워크 모델 구성과 데이터셋 설정은 위에서 이미 설명했으므로 생략하겠습니다.\n",
    "\n",
    "batchsize는 64이고 단일 GPU에서 15~16GB의 VRAM을 요구합니다.\n",
    "\n",
    "max_epoch은 150으로 잡혀있습니다.\n",
    "단일 RTX4090에서도 이틀정도 걸리는 긴 시간의 학습이 필요합니다.\n",
    "하지만, 10epoch마다 체크포인트가 \"Logs/{학습시작시간}\" 폴더에 저장되는데, 50epoch정도면 충분히 최고 성능으로 수렴하는 편입니다.\n",
    "그러므로, 재현성을 살펴보실때 굳이 끝까지 학습하실 필요는 없을 것 같습니다.\n",
    "\n",
    "AdamW 옵티마이저를 사용하였고, 10epoch 단위로 코사인어닐링 LR 스케쥴링을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04cffa1-13bc-498a-9ea7-3f8e95c9369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from mmengine.dataset import DefaultSampler, default_collate\n",
    "from mmengine.hooks import CheckpointHook, LoggerHook\n",
    "from mmengine.optim.scheduler import CosineRestartLR\n",
    "from mmengine.runner import Runner\n",
    "from torch.optim import AdamW\n",
    "\n",
    "def main():\n",
    "    input_chs = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    runner = Runner(\n",
    "        env_cfg=dict(\n",
    "            cudnn_benchmark=True,\n",
    "            mp_cfg=dict(mp_start_method=\"fork\", opencv_num_threads=0),\n",
    "            dist_cfg=dict(backend=\"nccl\"),\n",
    "        ),\n",
    "        model=dict(\n",
    "            type=OurBaseModel,\n",
    "            unet=dict(\n",
    "                type=UNet,\n",
    "                encoder=dict(\n",
    "                    type=RegNetEncoder,\n",
    "                    name=\"regnetx_002\",\n",
    "                    in_ch=len(input_chs),\n",
    "                    empty_out_depths=[],\n",
    "                ),\n",
    "                decoder=dict(\n",
    "                    type=UNetDecoder,\n",
    "                    decoder_chs=[128, 64, 48, 32],  # , 24],\n",
    "                    upsample_mode=\"nearest\",\n",
    "                    use_batchnorm=True,\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        train_dataloader=dict(\n",
    "            dataset=dict(\n",
    "                type=WildfireDataset,\n",
    "                mode=\"train\",\n",
    "                epoch_scale_factor=10.0,\n",
    "                kfold_N=0,\n",
    "                kfold_I=0,\n",
    "                input_chs=input_chs,\n",
    "            ),\n",
    "            batch_size=64,\n",
    "            sampler=dict(type=DefaultSampler, shuffle=True),\n",
    "            collate_fn=dict(type=default_collate),\n",
    "            num_workers=8,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        ),\n",
    "        train_cfg=dict(by_epoch=True, max_epochs=150),\n",
    "        optim_wrapper=dict(optimizer=dict(type=AdamW, lr=1e-3)),\n",
    "        param_scheduler=dict(\n",
    "            type=CosineRestartLR,\n",
    "            periods=[10] * 100,\n",
    "            restart_weights=[1] * 100,\n",
    "            eta_min=1e-6,\n",
    "            by_epoch=True,\n",
    "            convert_to_iter_based=True,\n",
    "        ),\n",
    "        default_hooks=dict(\n",
    "            checkpoint=dict(type=CheckpointHook, interval=10),\n",
    "            logger=dict(type=LoggerHook, interval=1000),\n",
    "        ),\n",
    "        work_dir=str(Path(\"Logs\") / datetime.now().strftime(\"%y%m%d_%H%M%S\")),\n",
    "    )\n",
    "\n",
    "    runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f164dc-956d-4d89-92dc-bc85a06d7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/27 13:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1516942946\n",
      "    GPU 0,1,2,3: NVIDIA GeForce RTX 4090\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.99\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.2.1+cu121\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.17.1+cu121\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1516942946\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/27 13:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/27 13:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "03/27 13:23:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Dataset WildfireDataset has no metainfo. ``dataset_meta`` in visualizer will be None.\n",
      "03/27 13:23:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/27 13:23:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/27 13:23:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /mnt/Projects/mm_from_139/aifactory_wildfire_challenge/submission_notebook/Logs/240327_132311.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
